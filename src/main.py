import os
import sys
import json
import requests
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import time
from loguru import logger

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'ignore')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'ignore')

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
LOGS_DIR = Path("logs")
LOGS_DIR.mkdir(exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()  # –£–¥–∞–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
logger.add(
    sys.stderr,
    format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
    level="INFO",
    colorize=True
)
logger.add(
    LOGS_DIR / "sync_ya_disk.log",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
    level="DEBUG",
    rotation="10 MB",
    retention="7 days",
    compression="zip"
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DOWNLOAD_DIR = "downloaded_files"
METADATA_FILE = "sync_metadata.json"
TOKEN = os.getenv('Token')
LARGE_FILE_SIZE = 300 * 1024 * 1024  # 300 –ú–ë –≤ –±–∞–π—Ç–∞—Ö
MAX_WORKERS = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
MAX_RETRIES = 3  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
RETRY_DELAY = 2  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö


class YandexDiskSyncer:
    def __init__(self, public_url, download_dir=DOWNLOAD_DIR, skip_large_files=False, max_workers=MAX_WORKERS):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞

        :param public_url: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫
        :param download_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        :param skip_large_files: –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã –±–æ–ª—å—à–µ 300 –ú–ë (—Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã)
        :param max_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        """
        self.public_url = public_url
        self.download_dir = Path(download_dir)
        self.metadata_file = Path(METADATA_FILE)
        self.token = TOKEN
        self.skip_large_files = skip_large_files
        self.max_workers = max_workers
        self.metadata = self.load_metadata()
        self.metadata_lock = Lock()  # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–º —Ä–µ–∂–∏–º–µ

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        self.download_dir.mkdir(exist_ok=True)

    @staticmethod
    def sanitize_filename(filename):
        """
        –£–¥–∞–ª—è–µ—Ç –∏–ª–∏ –∑–∞–º–µ–Ω—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞/–ø–∞–ø–∫–∏ –¥–ª—è Windows

        :param filename: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–∞–ø–∫–∏
        :return: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        """
        # –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ Windows: < > : " / \ | ? *
        invalid_chars = '<>:"/\\|?*'
        sanitized = filename

        # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        for char in invalid_chars:
            if char == '"':
                # –î–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ
                sanitized = sanitized.replace(char, "'")
            elif char in ['<', '>']:
                # –£–≥–ª–æ–≤—ã–µ —Å–∫–æ–±–∫–∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –∫—Ä—É–≥–ª—ã–µ
                sanitized = sanitized.replace('<', '(').replace('>', ')')
            else:
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ
                sanitized = sanitized.replace(char, '_')

        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        sanitized = sanitized.strip()

        # –ï—Å–ª–∏ –∏–º—è –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π –∏–ª–∏ –ø—Ä–æ–±–µ–ª–æ–º, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ
        if sanitized.endswith('.') or sanitized.endswith(' '):
            sanitized += '_'

        return sanitized

    def sanitize_path(self, path):
        """
        –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –æ—Ç–¥–µ–ª—å–Ω–æ

        :param path: –ü—É—Ç—å —Å –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        :return: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—É—Ç—å
        """
        if not path:
            return path

        # –†–∞–∑–±–∏–≤–∞–µ–º –ø—É—Ç—å –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        parts = path.split('/')
        # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        safe_parts = [self.sanitize_filename(part) for part in parts if part]
        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        return '/'.join(safe_parts)

    def _request_with_retry(self, method, url, max_retries=MAX_RETRIES, **kwargs):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç HTTP –∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

        :param method: HTTP –º–µ—Ç–æ–¥ ('get', 'post', –∏ —Ç.–¥.)
        :param url: URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        :param max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        :param kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è requests
        :return: Response –æ–±—ä–µ–∫—Ç –∏–ª–∏ None –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ
        """
        for attempt in range(max_retries):
            try:
                response = getattr(requests, method)(url, **kwargs)
                response.raise_for_status()
                return response
            except requests.exceptions.ConnectionError as e:
                if attempt < max_retries - 1:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                    logger.debug(f"ConnectionError: {e}")
                    time.sleep(RETRY_DELAY * (attempt + 1))
                    continue
                else:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    return None
            except requests.exceptions.Timeout as e:
                if attempt < max_retries - 1:
                    logger.warning(f"–¢–∞–π–º–∞—É—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                    logger.debug(f"Timeout: {e}")
                    time.sleep(RETRY_DELAY * (attempt + 1))
                    continue
                else:
                    logger.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    return None
            except requests.exceptions.HTTPError as e:
                logger.error(f"HTTP –æ—à–∏–±–∫–∞: {e}")
                return None
            except requests.exceptions.RequestException as e:
                if attempt < max_retries - 1:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                    logger.debug(f"RequestException: {e}")
                    time.sleep(RETRY_DELAY * (attempt + 1))
                    continue
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}")
                    return None
        return None

    def load_metadata(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö"""
        if self.metadata_file.exists():
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def save_metadata(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)

    def get_public_resources(self, public_key, path=None):
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ –ø—É–±–ª–∏—á–Ω–æ–π —Å—Å—ã–ª–∫–µ

        :param public_key: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ—Å—É—Ä—Å
        :param path: –ü—É—Ç—å –∫ –ø–æ–¥–ø–∞–ø–∫–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        :return: –î–∞–Ω–Ω—ã–µ —Ä–µ—Å—É—Ä—Å–∞
        """
        logger.debug(f"–ó–∞–ø—Ä–æ—Å –∫ API: public_key={public_key[:50]}..., path={path}")
        api_url = "https://cloud-api.yandex.net/v1/disk/public/resources"

        headers = {
            'Authorization': f'OAuth {self.token}'
        }

        params = {
            'public_key': public_key,
            'limit': 1000
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å, –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω
        if path:
            params['path'] = path

        logger.debug(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {api_url}")
        response = self._request_with_retry('get', api_url, headers=headers, params=params, timeout=30)
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {response is not None}")
        if response:
            return response.json()
        else:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è: {public_key}")
            if path:
                logger.debug(f"Path: {path}")
            return None

    def get_all_files_recursive(self, public_key, relative_path="", folders_set=None, root_public_key=None, _processed_folders=None):
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏

        :param public_key: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ—Å—É—Ä—Å
        :param relative_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        :param folders_set: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫
        :param root_public_key: –ö–æ—Ä–Ω–µ–≤–∞—è –ø—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è path –ø–∞—Ä–∞–º–µ—Ç—Ä–∞)
        :param _processed_folders: –°—á–µ—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞)
        :return: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        """
        if folders_set is None:
            folders_set = set()

        if _processed_folders is None:
            _processed_folders = {'count': 0}

        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é —Å—Å—ã–ª–∫—É
        if root_public_key is None:
            root_public_key = public_key

        files_list = []

        # –î–ª—è –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º public_key, –¥–ª—è –ø–æ–¥–ø–∞–ø–æ–∫ - path –ø–∞—Ä–∞–º–µ—Ç—Ä
        if relative_path:
            _processed_folders['count'] += 1
            if _processed_folders['count'] % 10 == 0:
                logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–ø–æ–∫: {_processed_folders['count']}")
            data = self.get_public_resources(root_public_key, path=f"/{relative_path}")
        else:
            logger.info("   –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏...")
            data = self.get_public_resources(public_key)

        if not data:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è: {relative_path if relative_path else '–∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞'}")
            return files_list

        if '_embedded' in data and 'items' in data['_embedded']:
            items = data['_embedded']['items']

            for item in items:
                item_name = item['name']
                item_type = item['type']
                item_path = f"{relative_path}/{item_name}" if relative_path else item_name

                if item_type == 'dir':
                    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –ø–∞–ø–∫—É
                    folders_set.add(item_path)  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É –≤ —Å–ø–∏—Å–æ–∫
                    item_public_url = item.get('public_url', '')

                    if item_public_url:
                        # –ï—Å–ª–∏ —É –ø–æ–¥–ø–∞–ø–∫–∏ –µ—Å—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π public_url, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                        # (API –≤–µ—Ä–Ω–µ—Ç –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã)
                        nested_files = self.get_all_files_recursive(
                            public_key=item_public_url,
                            relative_path=item_path,
                            folders_set=folders_set,
                            root_public_key=root_public_key if root_public_key else item_public_url,
                            _processed_folders=_processed_folders
                        )
                        files_list.extend(nested_files)
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç public_url, –∏—Å–ø–æ–ª—å–∑—É–µ–º path –ø–∞—Ä–∞–º–µ—Ç—Ä
                        # (API –º–æ–∂–µ—Ç –Ω–µ –≤–µ—Ä–Ω—É—Ç—å –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏)
                        nested_files = self.get_all_files_recursive(
                            public_key=root_public_key,
                            relative_path=item_path,
                            folders_set=folders_set,
                            root_public_key=root_public_key,
                            _processed_folders=_processed_folders
                        )
                        files_list.extend(nested_files)
                else:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–æ–∫
                    file_info = {
                        'name': item_name,
                        'path': item_path,
                        'size': item.get('size', 0),
                        'modified': item.get('modified', ''),
                        'md5': item.get('md5', ''),
                        'file': item.get('file', ''),
                        'public_url': item.get('public_url', '')
                    }
                    files_list.append(file_info)

        return files_list

    def download_file(self, file_info, root_public_key=None):
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞ (–∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –¥–ª—è –≤–∏–¥–µ–æ/–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)

        :param file_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
        :param root_public_key: –ö–æ—Ä–Ω–µ–≤–∞—è –ø—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö)
        :return: True –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–∫–∞—á–∞–Ω —É—Å–ø–µ—à–Ω–æ
        """
        # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–µ–π
        safe_path = self.sanitize_path(file_info['path'])
        local_path = self.download_dir / safe_path
        local_path.parent.mkdir(parents=True, exist_ok=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤–∏–¥–µ–æ
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.wmv', '.m4v', '.mpg', '.mpeg']
        file_ext = Path(file_info['name']).suffix.lower()

        if file_ext in video_extensions:
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –¥–ª—è –≤–∏–¥–µ–æ
            try:
                local_path.touch()
                logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –≤–∏–¥–µ–æ (—Å–æ–∑–¥–∞–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª): {file_info['path']} ({self.format_size(file_info['size'])})")
                return True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ {file_info['path']}: {e}")
                return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ñ–ª–∞–≥ –ø—Ä–æ–ø—É—Å–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        if self.skip_large_files and file_info['size'] > LARGE_FILE_SIZE:
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
            try:
                local_path.touch()
                logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª (—Å–æ–∑–¥–∞–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª): {file_info['path']} ({self.format_size(file_info['size'])})")
                return True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ {file_info['path']}: {e}")
                return False

        # –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ - —Å–∫–∞—á–∏–≤–∞–µ–º
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª
        download_url = file_info.get('file')

        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏, –ø–æ–ª—É—á–∞–µ–º –µ—ë —á–µ—Ä–µ–∑ API
        if not download_url:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º root_public_key –∏ path –¥–ª—è —Ñ–∞–π–ª–æ–≤ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
            file_public_url = file_info.get('public_url', '')
            if root_public_key and not file_public_url:
                # –§–∞–π–ª –≤ –ø–æ–¥–ø–∞–ø–∫–µ –±–µ–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ public_url
                download_url = self.get_download_link(root_public_key, path=f"/{file_info['path']}")
            elif file_public_url:
                # –§–∞–π–ª –∏–º–µ–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π public_url
                download_url = self.get_download_link(file_public_url)
            else:
                # –ù–µ—Ç –Ω–∏ root_public_key, –Ω–∏ public_url
                logger.debug(f"–û—Ç–ª–∞–¥–∫–∞: root_public_key={'–µ—Å—Ç—å' if root_public_key else '–Ω–µ—Ç'}, public_url={'–µ—Å—Ç—å' if file_public_url else '–Ω–µ—Ç'}")
                download_url = None

        if not download_url:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {file_info['path']}")
            return False

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª —Å retry
        for attempt in range(MAX_RETRIES):
            try:
                response = requests.get(download_url, stream=True, timeout=30)
                response.raise_for_status()

                # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                total_size = int(response.headers.get('content-length', 0))

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
                with open(local_path, 'wb') as f:
                    with tqdm(
                        total=total_size,
                        unit='B',
                        unit_scale=True,
                        unit_divisor=1024,
                        desc=file_info['name'][:30],
                        leave=False
                    ) as pbar:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                            pbar.update(len(chunk))

                logger.success(f"–°–∫–∞—á–∞–Ω: {file_info['path']} ({self.format_size(file_info['size'])})")
                return True

            except (requests.exceptions.RequestException, IOError) as e:
                if attempt < MAX_RETRIES - 1:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {file_info['path']} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{MAX_RETRIES})")
                    logger.debug(f"Download error: {e}")
                    time.sleep(RETRY_DELAY * (attempt + 1))
                    # –£–¥–∞–ª—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
                    if local_path.exists():
                        local_path.unlink()
                    continue
                else:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª {file_info['path']} –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    if local_path.exists():
                        local_path.unlink()
                    return False

        return False

    def get_download_link(self, public_url, path=None):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞

        :param public_url: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª
        :param path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        :return: URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        """
        if not public_url:
            return None

        api_url = "https://cloud-api.yandex.net/v1/disk/public/resources/download"

        headers = {
            'Authorization': f'OAuth {self.token}'
        }

        params = {
            'public_key': public_url
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å, –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω
        if path:
            params['path'] = path

        response = self._request_with_retry('get', api_url, headers=headers, params=params, timeout=30)
        if response:
            data = response.json()
            href = data.get('href')
            if not href:
                logger.warning(f"API –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ")
                logger.debug(f"public_key: {public_url[:50]}...")
                if path:
                    logger.debug(f"path: {path}")
            return href
        else:
            return None

    def should_download(self, file_info):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å–∫–∞—á–∏–≤–∞—Ç—å —Ñ–∞–π–ª

        :param file_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
        :return: True –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω—É–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å
        """
        file_path = file_info['path']
        safe_path = self.sanitize_path(file_path)
        local_path = self.download_dir / safe_path

        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ, —Å–∫–∞—á–∏–≤–∞–µ–º
        if not local_path.exists():
            return True

        # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ —Ñ–∞–π–ª–µ, —Å–∫–∞—á–∏–≤–∞–µ–º
        if file_path not in self.metadata:
            return True

        old_metadata = self.metadata[file_path]

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ –¥–∞—Ç–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if old_metadata.get('modified') != file_info['modified']:
            return True

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
        if old_metadata.get('size') != file_info['size']:
            return True

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ MD5 (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if file_info.get('md5') and old_metadata.get('md5') != file_info['md5']:
            return True

        return False

    def sync(self):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        """
        logger.info(f"–ù–∞—á–∞–ª–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å: {self.public_url}")
        logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {self.download_dir.absolute()}")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏ –ø–∞–ø–æ–∫
        logger.info("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤...")
        folders_set = set()
        all_files = self.get_all_files_recursive(self.public_url, folders_set=folders_set)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π URL –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏
        root_public_key = self.public_url

        if not all_files and not folders_set:
            logger.warning("–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")
            return

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫: {len(folders_set)}")

        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –ø–∞–ø–∫–∏, –¥–∞–∂–µ –ø—É—Å—Ç—ã–µ
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫...")
        for folder_path in sorted(folders_set):
            safe_folder_path = self.sanitize_path(folder_path)
            folder_full_path = self.download_dir / safe_folder_path
            folder_full_path.mkdir(parents=True, exist_ok=True)
        logger.success(f"–°–æ–∑–¥–∞–Ω–æ –ø–∞–ø–æ–∫: {len(folders_set)}")

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏...")
        files_to_download = []
        total_download_size = 0
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.wmv', '.m4v', '.mpg', '.mpeg']

        for file_info in all_files:
            if self.should_download(file_info):
                files_to_download.append(file_info)
                file_ext = Path(file_info['name']).suffix.lower()
                is_video = file_ext in video_extensions
                is_large = self.skip_large_files and file_info['size'] > LARGE_FILE_SIZE

                # –£—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
                if not is_video and not is_large:
                    total_download_size += file_info['size']

        logger.info("=" * 60)
        logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏:")
        logger.info(f"   –§–∞–π–ª–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ: {len(files_to_download)}")
        logger.info(f"   –û–±—â–∏–π –æ–±—ä–µ–º: {self.format_size(total_download_size)}")
        logger.info(f"   –§–∞–π–ª–æ–≤ —É–∂–µ —Å–∫–∞—á–∞–Ω–æ (–ø—Ä–æ–ø—É—â–µ–Ω–æ): {len(all_files) - len(files_to_download)}")
        logger.info(f"   –ü–æ—Ç–æ–∫–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {self.max_workers}")
        logger.info("=" * 60)

        if not files_to_download:
            logger.success("–í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
            return

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        downloaded_count = 0
        updated_count = 0
        skipped_count = len(all_files) - len(files_to_download)
        video_count = 0
        large_file_count = 0
        failed_files = []

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        def process_file(file_info):
            nonlocal downloaded_count, updated_count, video_count, large_file_count

            file_ext = Path(file_info['name']).suffix.lower()
            is_video = file_ext in video_extensions
            is_large = self.skip_large_files and file_info['size'] > LARGE_FILE_SIZE
            is_new = file_info['path'] not in self.metadata

            download_result = self.download_file(file_info, root_public_key=root_public_key)

            if download_result:
                # –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                with self.metadata_lock:
                    self.metadata[file_info['path']] = {
                        'size': file_info['size'],
                        'modified': file_info['modified'],
                        'md5': file_info['md5'],
                        'last_sync': datetime.now().isoformat(),
                        'is_video': is_video,
                        'is_large': is_large
                    }

                    if is_video:
                        video_count += 1
                    elif is_large:
                        large_file_count += 1
                    elif is_new:
                        downloaded_count += 1
                    else:
                        updated_count += 1

                return (True, file_info['path'])
            else:
                return (False, file_info['path'])

        # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤...")
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
            futures = {executor.submit(process_file, file_info): file_info for file_info in files_to_download}

            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            with tqdm(total=len(files_to_download), desc="–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å", unit="—Ñ–∞–π–ª") as pbar:
                for future in as_completed(futures):
                    success, file_path = future.result()
                    if not success:
                        failed_files.append(file_path)
                    pbar.update(1)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.save_metadata()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if failed_files:
            failed_log = Path('failed_downloads.txt')
            with open(failed_log, 'w', encoding='utf-8') as f:
                f.write('\n'.join(failed_files))
            logger.warning(f"–°–ø–∏—Å–æ–∫ –Ω–µ—É–¥–∞—á–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {failed_log.absolute()}")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("=" * 60)
        logger.success("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        logger.info("=" * 60)
        logger.info(f"–ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å–∫–∞—á–∞–Ω–æ: {downloaded_count}")
        logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {updated_count}")
        logger.info(f"–í–∏–¥–µ–æ (—Å–æ–∑–¥–∞–Ω—ã –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã): {video_count}")
        logger.info(f"–ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã >300–ú–ë (—Å–æ–∑–¥–∞–Ω—ã –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã): {large_file_count}")
        logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π): {skipped_count}")
        if failed_files:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {len(failed_files)}")
        logger.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")

    @staticmethod
    def format_size(size):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        for unit in ['–ë', '–ö–ë', '–ú–ë', '–ì–ë']:
            if size < 1024.0:
                return f"{size:.1f} {unit}"
            size /= 1024.0
        return f"{size:.1f} –¢–ë"


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if not TOKEN:
        logger.error("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return

    # –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫
    public_url = "https://disk.yandex.ru/d/_JeaJNmm6UeQVA"

    # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ skip_large_files=True, —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã –±–æ–ª—å—à–µ 300 –ú–ë
    syncer = YandexDiskSyncer(public_url, skip_large_files=True)
    syncer.sync()


if __name__ == "__main__":
    main()
